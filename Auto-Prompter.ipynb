{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrompt - Auto Write Evaluation Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Idea + TODOs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to know what the right prompt is, and it's hard to know if you've found it. This project aims to automate the process of finding the perfect evaluation prompt.\n",
    "\n",
    "**System IO:**\n",
    "\n",
    "- [ ] INPUT `PROMPT_IDEA_SEED`: A seed idea / guidance for the prompt to be written. For example: _Compare the writing style of two pieces of text. Score only the writing style, not the actual content meaning._\n",
    "- [ ] Input `TEXT_1`: With 500 words of Known Author writing\n",
    "- [ ] Input `TEXT_2`: Two examples:\n",
    "  - [ ] With 500 words of Unknown Author writing\n",
    "  - [ ] With 500 words of the same Known Author writing\n",
    "- [ ] Output: `SCORE`, the score from 1 - 10 of how similar the writing style is between the two pieces of text.\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- [ ] Build dataset file with:\n",
    "  - [ ] INPUT: `TEXT_1` and `TEXT_2` as inputs.\n",
    "  - [ ] OUTPUT: `SCORE` as output (1 if comparing to unknown and 10 if comparing to known same author).\n",
    "- [ ] Adapt the code below to auto write the prompt.\n",
    "- [ ] Replace usage of to_markdown() with a better format for long form text within the prompt.\n",
    "- [ ] Evaluation Goal (+/- 2 from the target score, within 1-10 limits):\n",
    "  - Comparing to Unknown Author must get a **score <= 3**,\n",
    "  - Comparing to Known Author must get a **score >= 7**.\n",
    "\n",
    "**Improvements:**\n",
    "\n",
    "- IDEA: Try providing last 3 diffs of the prompt changes, to help guide the next move.\n",
    "- Using Mixtral API cheaper? See [ChatMistralAI](https://js.langchain.com/docs/integrations/chat/mistral).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_prompt_from_answer, save_tmp_file\n",
    "from utils_multiline_table import df_to_multiline_table\n",
    "from data_handling import load_and_clean_dataset\n",
    "from eval import invoke_test_prompt_against_dataset\n",
    "from update_prompt import (\n",
    "    invoke_update_prompt,\n",
    "    previous_attempts_add,\n",
    "    previous_attempts_to_str,\n",
    ")\n",
    "from config import TMP_DIR, ROWS_INITIAL, IDEA_SEED, PROMPT_INIT_FILE, DATABASE_PATH\n",
    "\n",
    "import os\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main loop\n",
    "\n",
    "The main loop will run until the prompt is good enough (or max loops is reached).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT: TEXT_1</th>\n",
       "      <th>INPUT: TEXT_2</th>\n",
       "      <th>OUTPUT: SCORE_SAME_AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       INPUT: TEXT_1  \\\n",
       "0  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "1  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "2  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "3  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "\n",
       "                                       INPUT: TEXT_2  \\\n",
       "0  # Find the Best Travel Nursing Jobs\\n\\nLooking...   \n",
       "1  ## Background on Nursing Job Search Book\\n\\nTh...   \n",
       "2  # Find the Best Travel Nursing Jobs\\n\\nLooking...   \n",
       "3  ## Background on Nursing Job Search Book\\n\\nTh...   \n",
       "\n",
       "   OUTPUT: SCORE_SAME_AUTHOR  \n",
       "0                          9  \n",
       "1                          1  \n",
       "2                         10  \n",
       "3                          2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty ./_tmp directory\n",
    "for filename in os.listdir(TMP_DIR):\n",
    "    os.remove(os.path.join(TMP_DIR, filename))\n",
    "\n",
    "# Load the dataset\n",
    "# dataset_file = \"./datasets/sentiment_analysis_examples_10.csv\"\n",
    "dataset_file = \"./datasets/dataset-writing-style-v-not-v.xlsx\"\n",
    "df_all = load_and_clean_dataset(dataset_file)\n",
    "\n",
    "# If df_all has more rows than ROWS_INITIAL, take the first ROWS_INITIAL rows\n",
    "df_sample = df_all\n",
    "if len(df_all) > ROWS_INITIAL:\n",
    "    df_sample = df_all.head(ROWS_INITIAL)\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial prompt...\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain models\n",
    "set_llm_cache(SQLiteCache(database_path=DATABASE_PATH))\n",
    "model_gpt4 = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0.5, max_tokens=2000)\n",
    "model_gpt35 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=750)\n",
    "\n",
    "# Load the WRITEP prompt and set up the LangChain chain\n",
    "prompt_init = load_prompt(PROMPT_INIT_FILE)\n",
    "chain4 = prompt_init | model_gpt4 | StrOutputParser()\n",
    "\n",
    "# print(prompt_init.format(dataset_table=df_to_multiline_table(df_sample), idea_seed=IDEA_SEED))\n",
    "\n",
    "\n",
    "# Invoke the LangChain chain to generate the prompt\n",
    "save_tmp_file(\n",
    "    \"01-prompt_init.md\",\n",
    "    prompt_init.format(\n",
    "        dataset_table=df_to_multiline_table(df_sample), idea_seed=IDEA_SEED\n",
    "    ),\n",
    ")\n",
    "print(f\"Generating initial prompt...\")\n",
    "answer = chain4.invoke(\n",
    "    {\"dataset_table\": df_to_multiline_table(df_sample), \"idea_seed\": IDEA_SEED}\n",
    ")\n",
    "save_tmp_file(\"02-prompt_init-response.md\", answer)\n",
    "\n",
    "# Extract the generated prompt\n",
    "prompt_generated_str = \"\"\n",
    "prompt_generated_str = extract_prompt_from_answer(answer)\n",
    "prompt_generated_str = prompt_generated_str.replace(\n",
    "    \"%%%INPUT_TABLE%%%\", \"{input_table}\"\n",
    ")\n",
    "prompt_generated = PromptTemplate.from_template(prompt_generated_str)\n",
    "\n",
    "# print(prompt_generated_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 75.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>Thinking step by step</th>\n",
       "      <th>OUTPUT: SCORE_SAME_AUTHOR</th>\n",
       "      <th>INPUT: TEXT_1</th>\n",
       "      <th>INPUT: TEXT_2</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Is Correct?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Both texts use similar formatting, including h...</td>\n",
       "      <td>9</td>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both texts have a similar tone of providing in...</td>\n",
       "      <td>6</td>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Both texts have a similar tone, using a conver...</td>\n",
       "      <td>9</td>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The writing style of TEXT_1 is informative and...</td>\n",
       "      <td>2</td>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Both texts have a similar structure, with head...</td>\n",
       "      <td>9</td>\n",
       "      <td>### Taxable vs Tax Free Pay\\n\\nFollowing on fr...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Both texts have a similar tone of providing in...</td>\n",
       "      <td>5</td>\n",
       "      <td>### Taxable vs Tax Free Pay\\n\\nFollowing on fr...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Both texts use a conversational tone and engag...</td>\n",
       "      <td>9</td>\n",
       "      <td>### Top 5 Highest Paying States for Travel Nur...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Both texts have a different formatting style. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>### Top 5 Highest Paying States for Travel Nur...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ROW_NO                              Thinking step by step  \\\n",
       "0      0  Both texts use similar formatting, including h...   \n",
       "1      1  Both texts have a similar tone of providing in...   \n",
       "2      2  Both texts have a similar tone, using a conver...   \n",
       "3      3  The writing style of TEXT_1 is informative and...   \n",
       "4      4  Both texts have a similar structure, with head...   \n",
       "5      5  Both texts have a similar tone of providing in...   \n",
       "6      6  Both texts use a conversational tone and engag...   \n",
       "7      7  Both texts have a different formatting style. ...   \n",
       "\n",
       "   OUTPUT: SCORE_SAME_AUTHOR  \\\n",
       "0                          9   \n",
       "1                          6   \n",
       "2                          9   \n",
       "3                          2   \n",
       "4                          9   \n",
       "5                          5   \n",
       "6                          9   \n",
       "7                          1   \n",
       "\n",
       "                                       INPUT: TEXT_1  \\\n",
       "0  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "1  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "2  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "3  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "4  ### Taxable vs Tax Free Pay\\n\\nFollowing on fr...   \n",
       "5  ### Taxable vs Tax Free Pay\\n\\nFollowing on fr...   \n",
       "6  ### Top 5 Highest Paying States for Travel Nur...   \n",
       "7  ### Top 5 Highest Paying States for Travel Nur...   \n",
       "\n",
       "                                       INPUT: TEXT_2  Truth  Is Correct?  \n",
       "0  # Find the Best Travel Nursing Jobs\\n\\nLooking...      9         True  \n",
       "1  ## Background on Nursing Job Search Book\\n\\nTh...      1        False  \n",
       "2  # Find the Best Travel Nursing Jobs\\n\\nLooking...     10         True  \n",
       "3  ## Background on Nursing Job Search Book\\n\\nTh...      2         True  \n",
       "4  # Find the Best Travel Nursing Jobs\\n\\nLooking...      9         True  \n",
       "5  ## Background on Nursing Job Search Book\\n\\nTh...      2        False  \n",
       "6  # Find the Best Travel Nursing Jobs\\n\\nLooking...      8         True  \n",
       "7  ## Background on Nursing Job Search Book\\n\\nTh...      1         True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prompt counter used for the main loop\n",
    "i_prompt = 1\n",
    "\n",
    "df_generated, accuracy = invoke_test_prompt_against_dataset(\n",
    "    prompt_generated, df_all, model_gpt35, i_prompt\n",
    ")\n",
    "\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous attempts:\n",
      "### Attempt 1: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 50.00%\n",
      "Previous attempts:\n",
      "### Attempt 1: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 50.00% accuracy (4 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score must take into consideration elements such as syntax, vocabulary, punctuation, tone, and use of literary devices, rather than content, subject matter, or meaning.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 4\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 100.00%\n",
      "\n",
      "Final prompt saved with accuracy 100.00%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### Attempt 1: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 50.00% accuracy (4 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score must take into consideration elements such as syntax, vocabulary, punctuation, tone, and use of literary devices, rather than content, subject matter, or meaning.\n",
      "\n",
      "### Attempt 3: 100.00% accuracy (0 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a sentence to the instructions to emphasize that the presence of specific factual information, such as statistics, references, or specialized terminology, should not influence the score unless it directly pertains to the author's style.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous_attempts = []\n",
    "previous_attempts_add(previous_attempts, i_prompt, accuracy, \"First attempt.\")\n",
    "\n",
    "\n",
    "# Loop until accuracy is greater than 95% or 5 iterations have been reached\n",
    "try:\n",
    "    while accuracy < 90 and i_prompt < 7:\n",
    "        i_prompt = i_prompt + 1\n",
    "\n",
    "        previous_attempts_str = previous_attempts_to_str(previous_attempts, df_all)\n",
    "        print(f\"Previous attempts:\\n{previous_attempts_str}\\n\\n\")\n",
    "\n",
    "        prompt_previous = prompt_generated_str\n",
    "\n",
    "        prompt_generated_str, changes_made_str = invoke_update_prompt(\n",
    "            df_generated,\n",
    "            prompt_previous,\n",
    "            model_gpt4,\n",
    "            previous_attempts_str,\n",
    "            i_prompt=i_prompt,\n",
    "        )\n",
    "\n",
    "        prompt_updated = PromptTemplate.from_template(prompt_generated_str)\n",
    "        df_generated, accuracy = invoke_test_prompt_against_dataset(\n",
    "            prompt_updated, df_all, model_gpt35, i_prompt\n",
    "        )\n",
    "\n",
    "        previous_attempts_add(previous_attempts, i_prompt, accuracy, changes_made_str)\n",
    "\n",
    "    # print(f\"\\n\\nFinal prompt:\\n{prompt_generated_str}\")\n",
    "    save_tmp_file(\"10-prompt_final.md\", prompt_generated_str)\n",
    "    print(f\"\\nFinal prompt saved with accuracy {accuracy:.2f}%\")\n",
    "except ValueError as e:\n",
    "    if str(e) != \"TRUTH_IS_WRONG\":\n",
    "        raise e\n",
    "\n",
    "\n",
    "# print(json.dumps(previous_attempts, indent=2))\n",
    "print(\"\\n\\n\\n\\n\\n\\n\")\n",
    "print(previous_attempts_to_str(previous_attempts, df_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
