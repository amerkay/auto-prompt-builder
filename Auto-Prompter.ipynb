{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrompt - Auto Write Evaluation Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Idea + TODOs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to know what the right prompt is, and it's hard to know if you've found it. This project aims to automate the process of finding the perfect evaluation prompt.\n",
    "\n",
    "**System IO:**\n",
    "\n",
    "- [ ] INPUT `PROMPT_IDEA_SEED`: A seed idea / guidance for the prompt to be written. For example: _Compare the writing style of two pieces of text. Score only the writing style, not the actual content meaning._\n",
    "- [ ] Input `TEXT_1`: With 500 words of Known Author writing\n",
    "- [ ] Input `TEXT_2`: Two examples:\n",
    "  - [ ] With 500 words of Unknown Author writing\n",
    "  - [ ] With 500 words of the same Known Author writing\n",
    "- [ ] Output: `SCORE`, the score from 1 - 10 of how similar the writing style is between the two pieces of text.\n",
    "\n",
    "**Next steps:**\n",
    "\n",
    "- [ ] Build dataset file with:\n",
    "  - [ ] INPUT: `TEXT_1` and `TEXT_2` as inputs.\n",
    "  - [ ] OUTPUT: `SCORE` as output (1 if comparing to unknown and 10 if comparing to known same author).\n",
    "- [ ] Adapt the code below to auto write the prompt.\n",
    "- [ ] Replace usage of to_markdown() with a better format for long form text within the prompt.\n",
    "- [ ] Evaluation Goal (+/- 2 from the target score, within 1-10 limits):\n",
    "  - Comparing to Unknown Author must get a **score <= 3**,\n",
    "  - Comparing to Known Author must get a **score >= 7**.\n",
    "\n",
    "**Improvements:**\n",
    "\n",
    "- IDEA: Try providing last 3 diffs of the prompt changes, to help guide the next move.\n",
    "- Using Mixtral API cheaper? See [ChatMistralAI](https://js.langchain.com/docs/integrations/chat/mistral).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the utility functions from `utils.py``\n",
    "from utils import extract_prompt_from_answer, save_tmp_file\n",
    "from utils_multiline_table import df_to_multiline_table\n",
    "from data_handling import load_and_clean_dataset\n",
    "from eval import invoke_test_prompt_against_dataset\n",
    "from update_prompt import (\n",
    "    invoke_update_prompt,\n",
    "    previous_attempts_add,\n",
    "    previous_attempts_to_str,\n",
    ")\n",
    "from config import TMP_DIR, ROWS_INITIAL, IDEA_SEED, PROMPT_INIT_FILE\n",
    "\n",
    "import os\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main loop\n",
    "\n",
    "The main loop will run until the prompt is good enough (or max loops is reached).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT: TEXT_1</th>\n",
       "      <th>INPUT: TEXT_2</th>\n",
       "      <th>OUTPUT: SCORE_SAME_AUTHOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       INPUT: TEXT_1  \\\n",
       "0  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "1  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "2  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "3  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "\n",
       "                                       INPUT: TEXT_2  \\\n",
       "0  # Find the Best Travel Nursing Jobs\\n\\nLooking...   \n",
       "1  ## Background on Nursing Job Search Book\\n\\nTh...   \n",
       "2  # Find the Best Travel Nursing Jobs\\n\\nLooking...   \n",
       "3  ## Background on Nursing Job Search Book\\n\\nTh...   \n",
       "\n",
       "   OUTPUT: SCORE_SAME_AUTHOR  \n",
       "0                          9  \n",
       "1                          1  \n",
       "2                         10  \n",
       "3                          2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty ./_tmp directory\n",
    "for filename in os.listdir(TMP_DIR):\n",
    "    os.remove(os.path.join(TMP_DIR, filename))\n",
    "\n",
    "# Load the dataset\n",
    "# dataset_file = \"./datasets/sentiment_analysis_examples_10.csv\"\n",
    "dataset_file = \"./datasets/dataset-writing-style-v-not-v.xlsx\"\n",
    "df_all = load_and_clean_dataset(dataset_file)\n",
    "df_sample = df_all\n",
    "\n",
    "# If df_all has more rows than ROWS_INITIAL, take the first ROWS_INITIAL rows\n",
    "if len(df_all) > ROWS_INITIAL:\n",
    "    df_sample = df_all.head(ROWS_INITIAL)\n",
    "\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating initial prompt...\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain models\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "model_gpt4 = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0.5, max_tokens=2000)\n",
    "model_gpt35 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=750)\n",
    "\n",
    "# Load the WRITEP prompt and set up the LangChain chain\n",
    "prompt_init = load_prompt(PROMPT_INIT_FILE)\n",
    "chain4 = prompt_init | model_gpt4 | StrOutputParser()\n",
    "\n",
    "# print(prompt_init.format(dataset_table=df_to_multiline_table(df_sample), idea_seed=IDEA_SEED))\n",
    "\n",
    "\n",
    "# Invoke the LangChain chain to generate the prompt\n",
    "save_tmp_file(\n",
    "    \"01-prompt_init.md\",\n",
    "    prompt_init.format(\n",
    "        dataset_table=df_to_multiline_table(df_sample), idea_seed=IDEA_SEED\n",
    "    ),\n",
    ")\n",
    "print(f\"Generating initial prompt...\")\n",
    "answer = chain4.invoke(\n",
    "    {\"dataset_table\": df_to_multiline_table(df_sample), \"idea_seed\": IDEA_SEED}\n",
    ")\n",
    "save_tmp_file(\"02-prompt_init-response.md\", answer)\n",
    "\n",
    "# Extract the generated prompt\n",
    "prompt_generated_str = extract_prompt_from_answer(answer)\n",
    "prompt_generated_str = prompt_generated_str.replace(\n",
    "    \"%%%INPUT_TABLE%%%\", \"{input_table}\"\n",
    ")\n",
    "prompt_generated = PromptTemplate.from_template(prompt_generated_str)\n",
    "\n",
    "# print(prompt_generated_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 87.50%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>Thinking step by step</th>\n",
       "      <th>OUTPUT: SCORE_SAME_AUTHOR</th>\n",
       "      <th>INPUT: TEXT_1</th>\n",
       "      <th>INPUT: TEXT_2</th>\n",
       "      <th>Truth</th>\n",
       "      <th>Is Correct?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The use of bold and italicized text for emphas...</td>\n",
       "      <td>9</td>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The style of TEXT_1 is more of a guide with di...</td>\n",
       "      <td>1</td>\n",
       "      <td># The Ultimate Travel Nurse Salary Guide: 4 Mi...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The use of bold and italicized text for emphas...</td>\n",
       "      <td>9</td>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TEXT_1 provides a breakdown of a travel nurse'...</td>\n",
       "      <td>2</td>\n",
       "      <td>## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The use of bullet points, the conversational t...</td>\n",
       "      <td>9</td>\n",
       "      <td>### Taxable vs Tax Free Pay\\n\\nFollowing on fr...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>The use of bold text for emphasis, the convers...</td>\n",
       "      <td>3</td>\n",
       "      <td>### Taxable vs Tax Free Pay\\n\\nFollowing on fr...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The use of bullet points, bold text for headin...</td>\n",
       "      <td>9</td>\n",
       "      <td>### Top 5 Highest Paying States for Travel Nur...</td>\n",
       "      <td># Find the Best Travel Nursing Jobs\\n\\nLooking...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>The use of bold text for emphasis, the convers...</td>\n",
       "      <td>5</td>\n",
       "      <td>### Top 5 Highest Paying States for Travel Nur...</td>\n",
       "      <td>## Background on Nursing Job Search Book\\n\\nTh...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ROW_NO                              Thinking step by step  \\\n",
       "0      0  The use of bold and italicized text for emphas...   \n",
       "1      1  The style of TEXT_1 is more of a guide with di...   \n",
       "2      2  The use of bold and italicized text for emphas...   \n",
       "3      3  TEXT_1 provides a breakdown of a travel nurse'...   \n",
       "4      4  The use of bullet points, the conversational t...   \n",
       "5      5  The use of bold text for emphasis, the convers...   \n",
       "6      6  The use of bullet points, bold text for headin...   \n",
       "7      7  The use of bold text for emphasis, the convers...   \n",
       "\n",
       "   OUTPUT: SCORE_SAME_AUTHOR  \\\n",
       "0                          9   \n",
       "1                          1   \n",
       "2                          9   \n",
       "3                          2   \n",
       "4                          9   \n",
       "5                          3   \n",
       "6                          9   \n",
       "7                          5   \n",
       "\n",
       "                                       INPUT: TEXT_1  \\\n",
       "0  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "1  # The Ultimate Travel Nurse Salary Guide: 4 Mi...   \n",
       "2  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "3  ## Get A Travel Nurse Pay Breakdown\\n\\nUnderst...   \n",
       "4  ### Taxable vs Tax Free Pay\\n\\nFollowing on fr...   \n",
       "5  ### Taxable vs Tax Free Pay\\n\\nFollowing on fr...   \n",
       "6  ### Top 5 Highest Paying States for Travel Nur...   \n",
       "7  ### Top 5 Highest Paying States for Travel Nur...   \n",
       "\n",
       "                                       INPUT: TEXT_2  Truth  Is Correct?  \n",
       "0  # Find the Best Travel Nursing Jobs\\n\\nLooking...      9         True  \n",
       "1  ## Background on Nursing Job Search Book\\n\\nTh...      1         True  \n",
       "2  # Find the Best Travel Nursing Jobs\\n\\nLooking...     10         True  \n",
       "3  ## Background on Nursing Job Search Book\\n\\nTh...      2         True  \n",
       "4  # Find the Best Travel Nursing Jobs\\n\\nLooking...      9         True  \n",
       "5  ## Background on Nursing Job Search Book\\n\\nTh...      2         True  \n",
       "6  # Find the Best Travel Nursing Jobs\\n\\nLooking...      8         True  \n",
       "7  ## Background on Nursing Job Search Book\\n\\nTh...      1        False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prompt counter used for the main loop\n",
    "i_prompt = 1\n",
    "\n",
    "df_generated, accuracy = invoke_test_prompt_against_dataset(\n",
    "    prompt_generated, df_all, model_gpt35, i_prompt\n",
    ")\n",
    "\n",
    "df_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 1\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 75.00%\n",
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 75.00%\n",
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "### Attempt 3: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added the scoring scale (1, 5, 10) directly into the prompt for clarity and to ensure that the scoring system is used consistently.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 75.00%\n",
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "### Attempt 3: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added the scoring scale (1, 5, 10) directly into the prompt for clarity and to ensure that the scoring system is used consistently.\n",
      "\n",
      "### Attempt 4: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a note to emphasize that similarities in the content topic should not be confused with writing style and should not influence the scoring.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 75.00%\n",
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "### Attempt 3: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added the scoring scale (1, 5, 10) directly into the prompt for clarity and to ensure that the scoring system is used consistently.\n",
      "\n",
      "### Attempt 4: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a note to emphasize that similarities in the content topic should not be confused with writing style and should not influence the scoring.\n",
      "\n",
      "### Attempt 5: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a scoring guideline for intermediary scores (2-4, 6-9) to provide a more nuanced scale and address the issue with the incorrect score of 5 in the provided example. The new scoring guideline should help clarify the scoring process for cases that are not as clear-cut as the examples of scores 1, 5, and 10.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 87.50%\n",
      "Previous attempts:\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "### Attempt 3: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added the scoring scale (1, 5, 10) directly into the prompt for clarity and to ensure that the scoring system is used consistently.\n",
      "\n",
      "### Attempt 4: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a note to emphasize that similarities in the content topic should not be confused with writing style and should not influence the scoring.\n",
      "\n",
      "### Attempt 5: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a scoring guideline for intermediary scores (2-4, 6-9) to provide a more nuanced scale and address the issue with the incorrect score of 5 in the provided example. The new scoring guideline should help clarify the scoring process for cases that are not as clear-cut as the examples of scores 1, 5, and 10.\n",
      "\n",
      "### Attempt 6: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Specified that intermediate scores (2-4, 6-9) should be used to indicate varying degrees of similarity, with examples provided for when to use scores closer to 10 or 1.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Incorrect answers count: 1\n",
      "Pick the first 1 examples...\n",
      "Updating prompt using gpt-4-turbo...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Getting answer, chunk of 1 rows...\n",
      "Correct answers: 87.50%\n",
      "\n",
      "Final prompt saved with accuracy 87.50%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### Attempt 1: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "First attempt.\n",
      "\n",
      "### Attempt 2: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that the score should consider only the writing style and not the content or meaning of the texts.\n",
      "\n",
      "### Attempt 3: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added the scoring scale (1, 5, 10) directly into the prompt for clarity and to ensure that the scoring system is used consistently.\n",
      "\n",
      "### Attempt 4: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a note to emphasize that similarities in the content topic should not be confused with writing style and should not influence the scoring.\n",
      "\n",
      "### Attempt 5: 75.00% accuracy (2 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Added a scoring guideline for intermediary scores (2-4, 6-9) to provide a more nuanced scale and address the issue with the incorrect score of 5 in the provided example. The new scoring guideline should help clarify the scoring process for cases that are not as clear-cut as the examples of scores 1, 5, and 10.\n",
      "\n",
      "### Attempt 6: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Specified that intermediate scores (2-4, 6-9) should be used to indicate varying degrees of similarity, with examples provided for when to use scores closer to 10 or 1.\n",
      "\n",
      "### Attempt 7: 87.50% accuracy (1 wrong out of 8 test rows)\n",
      "Changes made:\n",
      "- Clarified that a score closer to 10 should be given when texts share many stylistic elements but may have subtle differences, instead of \"minor differences\" to better align with the provided incorrect answer where the score should have been higher due to the shared stylistic elements.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous_attempts = []\n",
    "previous_attempts_add(previous_attempts, i_prompt, accuracy, \"First attempt.\")\n",
    "\n",
    "\n",
    "# Loop until accuracy is greater than 95% or 5 iterations have been reached\n",
    "try:\n",
    "    while accuracy < 90 and i_prompt < 7:\n",
    "        i_prompt = i_prompt + 1\n",
    "\n",
    "        previous_attempts_str = previous_attempts_to_str(previous_attempts, df_all)\n",
    "        print(f\"Previous attempts:\\n{previous_attempts_str}\\n\\n\")\n",
    "\n",
    "        prompt_previous = prompt_generated_str\n",
    "\n",
    "        prompt_generated_str, changes_made_str = invoke_update_prompt(\n",
    "            df_generated,\n",
    "            prompt_previous,\n",
    "            model_gpt4,\n",
    "            previous_attempts_str,\n",
    "            i_prompt=i_prompt,\n",
    "        )\n",
    "\n",
    "        prompt_updated = PromptTemplate.from_template(prompt_generated_str)\n",
    "        df_generated, accuracy = invoke_test_prompt_against_dataset(\n",
    "            prompt_updated, df_all, model_gpt35, i_prompt\n",
    "        )\n",
    "\n",
    "        previous_attempts_add(previous_attempts, i_prompt, accuracy, changes_made_str)\n",
    "\n",
    "    # print(f\"\\n\\nFinal prompt:\\n{prompt_generated_str}\")\n",
    "    save_tmp_file(\"10-prompt_final.md\", prompt_generated_str)\n",
    "    print(f\"\\nFinal prompt saved with accuracy {accuracy:.2f}%\")\n",
    "except ValueError as e:\n",
    "    if str(e) != \"TRUTH_IS_WRONG\":\n",
    "        raise e\n",
    "\n",
    "\n",
    "# print(json.dumps(previous_attempts, indent=2))\n",
    "print(\"\\n\\n\\n\\n\\n\\n\")\n",
    "print(previous_attempts_to_str(previous_attempts, df_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
