{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrompt - Auto Write Evaluation Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to know what the right prompt is, and it's hard to know if you've found it. This project aims to automate the process of finding the perfect evaluation prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "from utils import save_tmp_file, load_model\n",
    "from data_handling import load_and_clean_dataset\n",
    "\n",
    "from strategies.sequential import SequentialStrategy\n",
    "from strategies.basic import BasicStrategy\n",
    "from strategies.tree_search import TreeSearchStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"./datasets/sentiment_analysis_examples_25.csv\"\n",
    "# DATASET_FILE = \"./datasets/dataset-writing-style-v-not-v.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style-30-100-words.xlsx\"\n",
    "\n",
    "# Seed Idea for prompt generation\n",
    "IDEA_SEED = \"\"\"Decide the sentiment of the input text.\"\"\"\n",
    "# IDEA_SEED = \"\"\"Compare the writing style of the two pieces of text. Your OUTPUT MUST ONLY take the writing style into consideration, NOT the meaning or thematic similarity of the texts.\"\"\".strip()\n",
    "\n",
    "\n",
    "# Initial prompt. If `None`, the initial prompt will be generated automatically\n",
    "# PROMPT_TO_EVAL_FILE = None\n",
    "# PROMPT_TO_EVAL_FILE = \"_scored_100/writing-style-01-gpt-turbo-3.5-temp-0.3.md\"\n",
    "\n",
    "# Maximum number of rows to use from the dataset for initial prompt generation\n",
    "ROWS_INITIAL = 6\n",
    "# Maximum number of rows in each chunk\n",
    "ROWS_MAX = 13\n",
    "# Number of rows to use as `incorrect` examples\n",
    "ROWS_INCORRECT = 4\n",
    "\n",
    "\n",
    "# Use Few or Zero Shot?\n",
    "IS_FEW_SHOT = True\n",
    "EVAL_CONCURRENCY = 4\n",
    "\n",
    "\n",
    "# Stopping criteria (inclusive)\n",
    "GOAL_ACCURACY = 98\n",
    "MAX_ATTEMPTS_PER_PLAN = 3\n",
    "\n",
    "\n",
    "# Model configurations\n",
    "# MODEL_PROMPT_WRITER_NAME = \"gpt-4-1106-preview\"\n",
    "MODEL_PROMPT_WRITER_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_PROMPT_WRITER_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "MODEL_PROMPT_WRITER_TEMPERATURE = 0.7\n",
    "MODEL_PROMPT_WRITER_MAX_TOKENS = 2400\n",
    "\n",
    "MODEL_EVALUATE_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_EVALUATE_NAME = \"gpt-4-1106-preview\"\n",
    "# MODEL_EVALUATE_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# MODEL_EVALUATE_NAME = \"togethercomputer/llama-2-70b-chat\"\n",
    "MODEL_EVALUATE_TEMPERATURE = 0.05\n",
    "MODEL_EVALUATE_MAX_TOKENS = 1600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling LLM cache...\n",
      "Loading ChatOpenAI model: gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kay/devel/auto-prompt-builder/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChatOpenAI model: gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kay/devel/auto-prompt-builder/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain models\n",
    "\n",
    "# if both model names start with `gpt-`, set cache\n",
    "if MODEL_PROMPT_WRITER_NAME.startswith(\"gpt-\") and MODEL_EVALUATE_NAME.startswith(\n",
    "    \"gpt-\"\n",
    "):\n",
    "    print(\"Enabling LLM cache...\")\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "# Setup the prompt writer model\n",
    "model_prompt_writer = load_model(\n",
    "    MODEL_PROMPT_WRITER_NAME,\n",
    "    MODEL_PROMPT_WRITER_TEMPERATURE,\n",
    "    MODEL_PROMPT_WRITER_MAX_TOKENS,\n",
    ")\n",
    "\n",
    "# Setup the evaluation model\n",
    "model_evaluate = load_model(\n",
    "    MODEL_EVALUATE_NAME,\n",
    "    MODEL_EVALUATE_TEMPERATURE,\n",
    "    MODEL_EVALUATE_MAX_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>INPUT: Sentence</th>\n",
       "      <th>OUTPUT: Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this new phone</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is just okay. Nothing special. üòê</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately, it broke the first day I used it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess it could've been worse üòÖ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waiting forever for a response... üòí</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The movie was both amazing and boring üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_NO                                  INPUT: Sentence OUTPUT: Sentiment\n",
       "0       1                            I love this new phone          positive\n",
       "1       2            This is just okay. Nothing special. üòê           neutral\n",
       "2       3  Unfortunately, it broke the first day I used it          negative\n",
       "3       4                 I guess it could've been worse üòÖ           neutral\n",
       "4       5              Waiting forever for a response... üòí          negative\n",
       "5       6          The movie was both amazing and boring üòï           neutral"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty ./_tmp directory\n",
    "for filename in os.listdir(\"_tmp\"):\n",
    "    os.remove(os.path.join(\"_tmp\", filename))\n",
    "\n",
    "# Load the dataset\n",
    "df_all = load_and_clean_dataset(DATASET_FILE)\n",
    "df_all.head(ROWS_INITIAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Auto Prompt Main Loop + Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 ranked ToT prompt construction plans...\n",
      "\n",
      "-> Running plan 5 with mutation 1...\n",
      "\n",
      "==============\n",
      "==============\n",
      "\n",
      "Plan 5:\n",
      "Decide the sentiment of the input text. Combine the approaches of NLP analysis, machine learning, psychological interpretation, and social media sentiment analysis. Utilize NLP techniques to preprocess the text, apply a trained machine learning model for sentiment prediction, consider psychological aspects of emotions, and incorporate sentiment scores from social media data. This comprehensive approach should provide an accurate determination of the sentiment as positive, negative, or neutral. \n",
      "\n",
      "Generating initial prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 92.00%\n",
      "Incorrect answers count: 2\n",
      "Pick the first 2 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n",
      "Correct answers: 92.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 92.00% accuracy (2 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 92.00% accuracy (2 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Clarified the steps to determine the sentiment in the prompt.\n",
      "---\n",
      "\n",
      "Incorrect answers count: 2\n",
      "Pick the first 2 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n",
      "Correct answers: 92.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 92.00% accuracy (2 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 92.00% accuracy (2 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Clarified the steps to determine the sentiment in the prompt.\n",
      "### Attempt 3: 92.00% accuracy (2 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 2:\n",
      "- Removed the \"Is Correct?\" field from the `Incorrect answers` section as it is not relevant to the prompt.\n",
      "- Added a new example in the `EXAMPLE` section to guide the model to handle sentences with emojis.\n",
      "- Removed the `Previous attempts to get higher accuracy` section as it is not relevant to the prompt.\n",
      "---\n",
      "\n",
      "\n",
      "-> Running plan 5 with mutation 2...\n",
      "\n",
      "==============\n",
      "==============\n",
      "\n",
      "Plan 5:\n",
      "Decide the sentiment of the input text. Combine the approaches of NLP analysis, machine learning, psychological interpretation, and social media sentiment analysis. Utilize NLP techniques to preprocess the text, apply a trained machine learning model for sentiment prediction, consider psychological aspects of emotions, and incorporate sentiment scores from social media data. This comprehensive approach should provide an accurate determination of the sentiment as positive, negative, or neutral.  \n",
      "\n",
      "Generating initial prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n",
      "Correct answers: 100.00%\n",
      ">>>> Goal accuracy 98% achieved for plan 5, mutation 2!\n",
      ">>>> Goal accuracy 98% achieved for plan 5, mutation 2!\n",
      "\n",
      "Final prompt saved with accuracy 100.00%\n",
      "Plan 5: Integrated Strategy Expert\n"
     ]
    }
   ],
   "source": [
    "# Setup the strategy executor\n",
    "# Options so far: SequentialStrategy, BasicStrategy, TreeSearchStrategy\n",
    "auto_prompt_strategy = TreeSearchStrategy(\n",
    "    model_prompt_writer=model_prompt_writer,\n",
    "    model_evaluate=model_evaluate,\n",
    "    df_original=df_all,\n",
    "    idea_seed=IDEA_SEED,\n",
    "    goal_accuracy=GOAL_ACCURACY,\n",
    "    max_attempts_per_plan=MAX_ATTEMPTS_PER_PLAN,\n",
    "    is_few_shot=IS_FEW_SHOT,\n",
    "    eval_concurrency=EVAL_CONCURRENCY,\n",
    "    rows_initial=ROWS_INITIAL,\n",
    "    rows_max=ROWS_MAX,\n",
    "    rows_incorrect=ROWS_INCORRECT,\n",
    "    is_use_eval_aware_dataset=True,\n",
    ")\n",
    "\n",
    "# Execute the strategy\n",
    "# prompt_str, accuracy, plan = auto_prompt_strategy.run()\n",
    "prompt_str, accuracy, plan = auto_prompt_strategy.run(max_mutations=2)\n",
    "\n",
    "# Save the final prompt\n",
    "save_tmp_file(\"10-prompt_final.md\", prompt_str)\n",
    "print(f\"\\nFinal prompt saved with accuracy {accuracy:.2f}%\")\n",
    "if plan is not None:\n",
    "    print(f\"Plan {plan.id}: {plan.expert_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an instance of the DatasetWithMistakeTracking class\n",
    "# dataset_tracker = EvalAwareDataset(df_all)\n",
    "\n",
    "# # Get initial sample of the dataset\n",
    "# df_sample = dataset_tracker.get_sample(ROWS_INITIAL)\n",
    "\n",
    "# # df_all\n",
    "# df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If PROMPT_TO_EVAL_FILE is not None, load the prompt from the file\n",
    "# prompt_str = \"\"\n",
    "# if PROMPT_TO_EVAL_FILE is not None:\n",
    "#     print(f\"Loading prompt from {PROMPT_TO_EVAL_FILE}\")\n",
    "#     with open(PROMPT_TO_EVAL_FILE, \"r\") as f:\n",
    "#         prompt_str = f.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
