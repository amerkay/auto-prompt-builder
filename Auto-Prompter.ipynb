{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrompt - Auto Write Evaluation Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Idea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to know what the right prompt is, and it's hard to know if you've found it. This project aims to automate the process of finding the perfect evaluation prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "from utils import save_tmp_file, load_model\n",
    "from data_handling import load_and_clean_dataset, get_df_incorrect_answers\n",
    "from evaluate_against_dataset import EvaluateAgainstDataset\n",
    "from generate_prompt_initial import GeneratePromptInitial\n",
    "from generate_prompt_update import GeneratePromptUpdate\n",
    "from generate_expert_plans import GenerateExpertPlans\n",
    "from previous_attempts import PreviousAttempts, Attempt\n",
    "from eval_aware_dataset import EvalAwareDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"./datasets/sentiment_analysis_examples_25.csv\"\n",
    "# DATASET_FILE = \"./datasets/dataset-writing-style-v-not-v.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style-30-100-words.xlsx\"\n",
    "\n",
    "# Seed Idea for prompt generation\n",
    "IDEA_SEED = \"\"\"Decide the sentiment of the input text.\"\"\"\n",
    "# IDEA_SEED = \"\"\"Compare the writing style of the two pieces of text. Your OUTPUT MUST ONLY take the writing style into consideration, NOT the meaning or thematic similarity of the texts.\"\"\".strip()\n",
    "\n",
    "\n",
    "# Initial prompt. If `None`, the initial prompt will be generated automatically\n",
    "# PROMPT_TO_EVAL_FILE = None\n",
    "# PROMPT_TO_EVAL_FILE = \"_scored_100/writing-style-01-gpt-turbo-3.5-temp-0.3.md\"\n",
    "\n",
    "# Maximum number of rows to use from the dataset for initial prompt generation\n",
    "ROWS_INITIAL = 8\n",
    "# Maximum number of rows in each chunk\n",
    "ROWS_MAX = 13\n",
    "# Number of rows to use as `incorrect` examples\n",
    "ROWS_INCORRECT = 5\n",
    "\n",
    "\n",
    "# Use Few or Zero Shot?\n",
    "IS_FEW_SHOT = True\n",
    "EVAL_CONCURRENCY = 10\n",
    "\n",
    "\n",
    "# Stopping criteria (inclusive)\n",
    "GOAL_ACCURACY = 98\n",
    "MAX_ATTEMPTS_PER_PLAN = 1\n",
    "\n",
    "\n",
    "# Model configurations\n",
    "# MODEL_PROMPT_WRITER_NAME = \"gpt-4-1106-preview\"\n",
    "MODEL_PROMPT_WRITER_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_PROMPT_WRITER_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "MODEL_PROMPT_WRITER_TEMPERATURE = 0.6\n",
    "MODEL_PROMPT_WRITER_MAX_TOKENS = 2000\n",
    "\n",
    "MODEL_EVALUATE_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_EVALUATE_NAME = \"gpt-4-1106-preview\"\n",
    "# MODEL_EVALUATE_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# MODEL_EVALUATE_NAME = \"togethercomputer/llama-2-70b-chat\"\n",
    "MODEL_EVALUATE_TEMPERATURE = 0.01\n",
    "MODEL_EVALUATE_MAX_TOKENS = 1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling LLM cache...\n",
      "Loading ChatOpenAI model: gpt-3.5-turbo\n",
      "Loading ChatOpenAI model: gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain models\n",
    "\n",
    "# if both model names start with `gpt-`, set cache\n",
    "if MODEL_PROMPT_WRITER_NAME.startswith(\"gpt-\") and MODEL_EVALUATE_NAME.startswith(\n",
    "    \"gpt-\"\n",
    "):\n",
    "    print(\"Enabling LLM cache...\")\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "# Setup the prompt writer model\n",
    "model_prompt_writer = load_model(\n",
    "    MODEL_PROMPT_WRITER_NAME,\n",
    "    MODEL_PROMPT_WRITER_TEMPERATURE,\n",
    "    MODEL_PROMPT_WRITER_MAX_TOKENS,\n",
    ")\n",
    "\n",
    "# Setup the evaluation model\n",
    "model_evaluate = load_model(\n",
    "    MODEL_EVALUATE_NAME,\n",
    "    MODEL_EVALUATE_TEMPERATURE,\n",
    "    MODEL_EVALUATE_MAX_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>INPUT: Sentence</th>\n",
       "      <th>OUTPUT: Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this new phone</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is just okay. Nothing special. üòê</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately, it broke the first day I used it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess it could've been worse üòÖ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waiting forever for a response... üòí</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The movie was both amazing and boring üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Not sure if I liked it or not</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Absolutely fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_NO                                  INPUT: Sentence OUTPUT: Sentiment\n",
       "0       1                            I love this new phone          positive\n",
       "1       2            This is just okay. Nothing special. üòê           neutral\n",
       "2       3  Unfortunately, it broke the first day I used it          negative\n",
       "3       4                 I guess it could've been worse üòÖ           neutral\n",
       "4       5              Waiting forever for a response... üòí          negative\n",
       "5       6          The movie was both amazing and boring üòï           neutral\n",
       "6       7                    Not sure if I liked it or not           neutral\n",
       "7       8                 Absolutely fantastic experience!          positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty ./_tmp directory\n",
    "for filename in os.listdir(\"_tmp\"):\n",
    "    os.remove(os.path.join(\"_tmp\", filename))\n",
    "\n",
    "# Load the dataset\n",
    "df_all = load_and_clean_dataset(DATASET_FILE)\n",
    "\n",
    "# Create an instance of the DatasetWithMistakeTracking class\n",
    "dataset_tracker = EvalAwareDataset(df_all)\n",
    "\n",
    "# Get initial sample of the dataset\n",
    "df_sample = dataset_tracker.get_sample(ROWS_INITIAL)\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Initial Expert Ideas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 ranked ToT prompt construction plans...\n",
      "\n",
      "=====================\n",
      "=====================\n",
      "\n",
      "Plan 5:\n",
      "Decide the sentiment of the input text. Combine the sentiment analysis model, lexicon-based approach, emotion recognition techniques, and psychological analysis. Use the sentiment analysis model as the primary method and leverage the other approaches as additional validation. Cross-reference the predictions from different methods to determine the most accurate sentiment classification. \n",
      "\n",
      "Generating initial prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n",
      "Correct answers: 92.00%\n",
      "\n",
      "=====================\n",
      "=====================\n",
      "\n",
      "Plan 1:\n",
      "Decide the sentiment of the input text. Train a sentiment analysis model using a large labeled dataset. Fine-tune the model using transfer learning techniques on a smaller domain-specific dataset. Use the trained model to predict the sentiment of the input text as positive, negative, or neutral. \n",
      "\n",
      "Generating initial prompt...\n",
      "Getting chunk 1 retry 0 with 13 rows...\n",
      "Getting chunk 2 retry 0 with 12 rows...\n",
      "Correct answers: 100.00%\n",
      "\n",
      "Final prompt saved with accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Generate the expert ToT plans\n",
    "gen_expert_plans = GenerateExpertPlans(\n",
    "    model=model_prompt_writer, df_sample=df_sample, idea_seed=IDEA_SEED\n",
    ")\n",
    "ranked_expert_plans = gen_expert_plans.invoke()\n",
    "# print(json.dumps(ranked_expert_plans, indent=2))\n",
    "\n",
    "# Create an instance of the EvalAgainstDataset class\n",
    "evaluator = EvaluateAgainstDataset(\n",
    "    model=model_evaluate,\n",
    "    df_original=df_all,\n",
    "    max_chunk_rows=ROWS_MAX,\n",
    "    concurrency=EVAL_CONCURRENCY,\n",
    ")\n",
    "\n",
    "# Init global variables\n",
    "previous_attempts, prompt_str, accuracy = None, None, None\n",
    "\n",
    "# Loop through the expert plans\n",
    "for i, plan in enumerate(ranked_expert_plans):\n",
    "    # if plan.id != 5:\n",
    "    #     continue\n",
    "    \n",
    "    # The prompt counter used for the main loop\n",
    "    attempt_no = 1\n",
    "\n",
    "    # The previous attempts list\n",
    "    previous_attempts = PreviousAttempts(df_all_length=len(df_all))\n",
    "\n",
    "    # the plan\n",
    "    plan_text = plan.to_string(idea_seed=IDEA_SEED)\n",
    "\n",
    "    print(\"\\n=====================\\n=====================\\n\")\n",
    "    print(f\"Plan {plan.id}:\")\n",
    "    print(plan_text, \"\\n\")\n",
    "\n",
    "    # Generate the initial prompt for this plan\n",
    "    gen_prompt_initial = GeneratePromptInitial(\n",
    "        model=model_prompt_writer,\n",
    "        is_few_shot=IS_FEW_SHOT,\n",
    "        df_sample=df_sample,\n",
    "        idea_seed=plan_text,\n",
    "        plan_id=plan.id,\n",
    "    )\n",
    "    prompt_str = gen_prompt_initial.invoke()\n",
    "\n",
    "    # Test the Initial Prompt against the dataset\n",
    "    df_generated, accuracy = evaluator.invoke(\n",
    "        prompt_str=prompt_str, plan_id=plan.id, attempt_no=attempt_no\n",
    "    )\n",
    "\n",
    "    # Get the incorrect answers and update the previous mistakes\n",
    "    df_incorrect = get_df_incorrect_answers(df_generated)\n",
    "    dataset_tracker.update_mistakes(df_incorrect)\n",
    "\n",
    "    # Add the initial attempt to the previous attempts list\n",
    "    previous_attempts.add(\n",
    "        Attempt(attempt_no=attempt_no, accuracy=accuracy, changes_made=\"First attempt.\")\n",
    "    )\n",
    "\n",
    "    ## The Main loop to auto-magically improve the prompt ###\n",
    "    ## Runs until the prompt is good enough (or max loops is reached).\n",
    "    while accuracy < GOAL_ACCURACY and attempt_no < MAX_ATTEMPTS_PER_PLAN:\n",
    "        attempt_no = attempt_no + 1\n",
    "        \n",
    "        # Generate the updated prompt for this plan\n",
    "        gen_prompt_update = GeneratePromptUpdate(\n",
    "            model=model_prompt_writer,\n",
    "            attempt_no=attempt_no,\n",
    "            plan_id=plan.id,\n",
    "            idea_seed=plan_text,\n",
    "            previous_attempts=previous_attempts,\n",
    "            max_rows_incorrect=ROWS_INCORRECT,\n",
    "        )\n",
    "        prompt_str, changes_made_str = gen_prompt_update.invoke_with_retry(\n",
    "            df_generated=df_generated,\n",
    "            prompt_previous=prompt_str,\n",
    "        )\n",
    "\n",
    "        # Test the Updated Prompt against the dataset\n",
    "        df_generated, accuracy = evaluator.invoke(\n",
    "            prompt_str=prompt_str, plan_id=plan.id, attempt_no=attempt_no\n",
    "        )\n",
    "\n",
    "        # Get the incorrect answers and update the previous mistakes\n",
    "        df_incorrect = get_df_incorrect_answers(df_generated)\n",
    "        dataset_tracker.update_mistakes(df_incorrect)\n",
    "\n",
    "        previous_attempts.add(\n",
    "            Attempt(\n",
    "                attempt_no=attempt_no, accuracy=accuracy, changes_made=changes_made_str\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # print(json.dumps(previous_attempts, indent=2))\n",
    "        print(\"\\n---\\n\" + previous_attempts.to_string() + \"---\\n\")\n",
    "\n",
    "    if accuracy >= GOAL_ACCURACY:\n",
    "        break\n",
    "\n",
    "    if i >= 1:\n",
    "        print(f\"TEMP: Stopping because we've tried {i+1} plans already.\")\n",
    "        break\n",
    "\n",
    "\n",
    "# print(f\"\\n\\nFinal prompt:\\n{prompt_generated_str}\")\n",
    "save_tmp_file(\"10-prompt_final.md\", prompt_str)\n",
    "print(f\"\\nFinal prompt saved with accuracy {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>INPUT: Sentence</th>\n",
       "      <th>OUTPUT: Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess it could've been worse üòÖ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The movie was both amazing and boring üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this new phone</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is just okay. Nothing special. üòê</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately, it broke the first day I used it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waiting forever for a response... üòí</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Not sure if I liked it or not</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Absolutely fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_NO                                  INPUT: Sentence OUTPUT: Sentiment\n",
       "3       4                 I guess it could've been worse üòÖ           neutral\n",
       "5       6          The movie was both amazing and boring üòï           neutral\n",
       "0       1                            I love this new phone          positive\n",
       "1       2            This is just okay. Nothing special. üòê           neutral\n",
       "2       3  Unfortunately, it broke the first day I used it          negative\n",
       "4       5              Waiting forever for a response... üòí          negative\n",
       "6       7                    Not sure if I liked it or not           neutral\n",
       "7       8                 Absolutely fantastic experience!          positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tracker.get_sample(ROWS_INITIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>INPUT: Sentence</th>\n",
       "      <th>OUTPUT: Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this new phone</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is just okay. Nothing special. üòê</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately, it broke the first day I used it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess it could've been worse üòÖ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waiting forever for a response... üòí</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The movie was both amazing and boring üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Not sure if I liked it or not</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Absolutely fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mediocre service, wouldn't recommend üòë</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Hard to tell if it's good or bad üò∂</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>The food was great but the service was terrible üôÅ</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Totally exceeded my expectations! üòä</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Barely functional and not worth the price.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>A masterpiece of visual art and storytelling! üåü</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Found it quite boring and uneventful. üò¥</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>I'm torn between loving and hating it ü§î</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>It's just average, nothing more or less. ü§∑‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Surprisingly good for the price!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Not what I expected, quite disappointing.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Feels like it could go either way üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Pretty standard experience, nothing unique.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>An absolute joy to use, highly recommend! üòÅ</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Meh, I've seen better.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Could be good or bad, hard to say ü§∑</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Ordinary and unremarkable in every way.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROW_NO                                    INPUT: Sentence  \\\n",
       "0        1                              I love this new phone   \n",
       "1        2              This is just okay. Nothing special. üòê   \n",
       "2        3    Unfortunately, it broke the first day I used it   \n",
       "3        4                   I guess it could've been worse üòÖ   \n",
       "4        5                Waiting forever for a response... üòí   \n",
       "5        6            The movie was both amazing and boring üòï   \n",
       "6        7                      Not sure if I liked it or not   \n",
       "7        8                   Absolutely fantastic experience!   \n",
       "8        9             Mediocre service, wouldn't recommend üòë   \n",
       "9       10                 Hard to tell if it's good or bad üò∂   \n",
       "10      11  The food was great but the service was terrible üôÅ   \n",
       "11      12                Totally exceeded my expectations! üòä   \n",
       "12      13         Barely functional and not worth the price.   \n",
       "13      14    A masterpiece of visual art and storytelling! üåü   \n",
       "14      15            Found it quite boring and uneventful. üò¥   \n",
       "15      16            I'm torn between loving and hating it ü§î   \n",
       "16      17      It's just average, nothing more or less. ü§∑‚Äç‚ôÇÔ∏è   \n",
       "17      18                   Surprisingly good for the price!   \n",
       "18      19          Not what I expected, quite disappointing.   \n",
       "19      20                Feels like it could go either way üòï   \n",
       "20      21        Pretty standard experience, nothing unique.   \n",
       "21      22        An absolute joy to use, highly recommend! üòÅ   \n",
       "22      23                             Meh, I've seen better.   \n",
       "23      24                Could be good or bad, hard to say ü§∑   \n",
       "24      25            Ordinary and unremarkable in every way.   \n",
       "\n",
       "   OUTPUT: Sentiment  \n",
       "0           positive  \n",
       "1            neutral  \n",
       "2           negative  \n",
       "3            neutral  \n",
       "4           negative  \n",
       "5            neutral  \n",
       "6            neutral  \n",
       "7           positive  \n",
       "8           negative  \n",
       "9            neutral  \n",
       "10          negative  \n",
       "11          positive  \n",
       "12          negative  \n",
       "13          positive  \n",
       "14          negative  \n",
       "15           neutral  \n",
       "16           neutral  \n",
       "17          positive  \n",
       "18          negative  \n",
       "19           neutral  \n",
       "20           neutral  \n",
       "21          positive  \n",
       "22          negative  \n",
       "23           neutral  \n",
       "24           neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If PROMPT_TO_EVAL_FILE is not None, load the prompt from the file\n",
    "# prompt_str = \"\"\n",
    "# if PROMPT_TO_EVAL_FILE is not None:\n",
    "#     print(f\"Loading prompt from {PROMPT_TO_EVAL_FILE}\")\n",
    "#     with open(PROMPT_TO_EVAL_FILE, \"r\") as f:\n",
    "#         prompt_str = f.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
