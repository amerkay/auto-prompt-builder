{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoPrompt - Auto Write Evaluation Prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to know what the right prompt is, and it's hard to know if you've found it. This project aims to automate the process of finding the perfect evaluation prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "from utils import save_log_file, load_model\n",
    "from data_handling import load_and_clean_dataset\n",
    "\n",
    "from strategies.sequential import SequentialStrategy\n",
    "from strategies.basic import BasicStrategy\n",
    "from strategies.tree_search import TreeSearchStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE = \"./datasets/sentiment_analysis_examples_25.csv\"\n",
    "# DATASET_FILE = \"./datasets/dataset-writing-style-v-not-v.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style.xlsx\"\n",
    "# DATASET_FILE = \"./datasets/writing-style-30-100-words.xlsx\"\n",
    "\n",
    "# Seed Idea for prompt generation\n",
    "IDEA_SEED = \"\"\"Decide the sentiment of the input text.\"\"\"\n",
    "# IDEA_SEED = \"\"\"Compare the two pieces of text. Your OUTPUT MUST ONLY take the writing style, voice, tone and stucture into consideration. Do not consider the meaning or thematic similarity of the texts.\"\"\".strip()\n",
    "\n",
    "\n",
    "# Initial prompt. If `None`, the initial prompt will be generated automatically\n",
    "# PROMPT_TO_EVAL_FILE = None\n",
    "# PROMPT_TO_EVAL_FILE = \"_scored_100/writing-style-01-gpt-turbo-3.5-temp-0.3.md\"\n",
    "\n",
    "# Maximum number of rows to use from the dataset for initial prompt generation\n",
    "ROWS_INITIAL = 10\n",
    "# Maximum number of rows in each chunk\n",
    "ROWS_MAX = 15\n",
    "# Number of rows to use as `incorrect` examples\n",
    "ROWS_INCORRECT = 5\n",
    "\n",
    "\n",
    "# Use Few or Zero Shot?\n",
    "IS_FEW_SHOT = True\n",
    "EVAL_CONCURRENCY = 10\n",
    "\n",
    "\n",
    "# Stopping criteria (inclusive)\n",
    "GOAL_ACCURACY = 99\n",
    "MAX_ATTEMPTS_PER_PLAN = 5 # including the initial attempt before using UPDATEP\n",
    "\n",
    "\n",
    "# Model configurations\n",
    "# MODEL_PROMPT_WRITER_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_PROMPT_WRITER_NAME = \"gpt-4-1106-preview\"\n",
    "MODEL_PROMPT_WRITER_NAME = \"gpt-3.5-turbo-16k\"\n",
    "# MODEL_PROMPT_WRITER_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "MODEL_PROMPT_WRITER_TEMPERATURE = 0.7\n",
    "MODEL_PROMPT_WRITER_MAX_TOKENS = 2200\n",
    "\n",
    "MODEL_EVALUATE_NAME = \"gpt-3.5-turbo\"\n",
    "# MODEL_EVALUATE_NAME = \"gpt-3.5-turbo-16k\"\n",
    "# MODEL_EVALUATE_NAME = \"gpt-4-1106-preview\"\n",
    "# MODEL_EVALUATE_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# MODEL_EVALUATE_NAME = \"togethercomputer/llama-2-70b-chat\"\n",
    "MODEL_EVALUATE_TEMPERATURE = 0.1\n",
    "MODEL_EVALUATE_MAX_TOKENS = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling LLM cache...\n",
      "Loading ChatOpenAI model: gpt-3.5-turbo-16k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kay/devel/auto-prompt-builder/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChatOpenAI model: gpt-3.5-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kay/devel/auto-prompt-builder/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Set up LangChain models\n",
    "\n",
    "# if both model names start with `gpt-`, set cache\n",
    "if MODEL_PROMPT_WRITER_NAME.startswith(\"gpt-\") and MODEL_EVALUATE_NAME.startswith(\n",
    "    \"gpt-\"\n",
    "):\n",
    "    print(\"Enabling LLM cache...\")\n",
    "    set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
    "\n",
    "\n",
    "# Setup the prompt writer model\n",
    "model_prompt_writer = load_model(\n",
    "    MODEL_PROMPT_WRITER_NAME,\n",
    "    MODEL_PROMPT_WRITER_TEMPERATURE,\n",
    "    MODEL_PROMPT_WRITER_MAX_TOKENS,\n",
    ")\n",
    "\n",
    "# Setup the evaluation model\n",
    "model_evaluate = load_model(\n",
    "    MODEL_EVALUATE_NAME,\n",
    "    MODEL_EVALUATE_TEMPERATURE,\n",
    "    MODEL_EVALUATE_MAX_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_NO</th>\n",
       "      <th>INPUT_Sentence</th>\n",
       "      <th>OUTPUT_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I love this new phone</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This is just okay. Nothing special. üòê</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Unfortunately, it broke the first day I used it</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I guess it could've been worse üòÖ</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Waiting forever for a response... üòí</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The movie was both amazing and boring üòï</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Not sure if I liked it or not</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Absolutely fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mediocre service, wouldn't recommend üòë</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Hard to tell if it's good or bad üò∂</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROW_NO                                   INPUT_Sentence OUTPUT_Sentiment\n",
       "0       1                            I love this new phone         positive\n",
       "1       2            This is just okay. Nothing special. üòê          neutral\n",
       "2       3  Unfortunately, it broke the first day I used it         negative\n",
       "3       4                 I guess it could've been worse üòÖ          neutral\n",
       "4       5              Waiting forever for a response... üòí         negative\n",
       "5       6          The movie was both amazing and boring üòï          neutral\n",
       "6       7                    Not sure if I liked it or not          neutral\n",
       "7       8                 Absolutely fantastic experience!         positive\n",
       "8       9           Mediocre service, wouldn't recommend üòë         negative\n",
       "9      10               Hard to tell if it's good or bad üò∂          neutral"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create it if it does not exist, or empty ./_log directory if it does\n",
    "if not os.path.exists(\"_log\"):\n",
    "    os.mkdir(\"_log\")\n",
    "else:\n",
    "    for filename in os.listdir(\"_log\"):\n",
    "        os.remove(os.path.join(\"_log\", filename))\n",
    "\n",
    "# Load the dataset\n",
    "df_all = load_and_clean_dataset(DATASET_FILE)\n",
    "df_all.head(ROWS_INITIAL)\n",
    "\n",
    "from utils_xml_table import slugify_column_names\n",
    "slugify_column_names(df_all).head(ROWS_INITIAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Auto Prompt Main Loop + Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 ranked ToT prompt construction plans...\n",
      "\n",
      "-> Running plan 5 with mutation 1...\n",
      "\n",
      "==============\n",
      "==============\n",
      "\n",
      "Plan 5:\n",
      "Decide the sentiment of the input text. Combine NLP techniques, machine learning models, psychological analysis, and social media data. Use sentiment analysis algorithms to analyze the text and classify it as positive, negative, or neutral. Consider psychological aspects and emotional cues in the text. Additionally, leverage social media data and sentiment analysis tools to enhance the accuracy of sentiment classification. \n",
      "\n",
      "Generating initial prompt...\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n",
      "Correct answers: 88.00%\n",
      "Incorrect answers count: 3\n",
      "Pick the first 3 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answers: 88.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Updated the prompt instructions for clarity and accuracy.\n",
      "---\n",
      "\n",
      "Incorrect answers count: 3\n",
      "Pick the first 3 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      ">> Total cost: 0.009 USD, tokens used 2696\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n",
      "Correct answers: 88.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Updated the prompt instructions for clarity and accuracy.\n",
      "### Attempt 3: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 2:\n",
      "- Clarified the importance of considering social media data in the sentiment analysis.\n",
      "- Emphasized the need to leverage psychological analysis to enhance the accuracy of sentiment classification.\n",
      "- Added examples to guide the sentiment analysis process.\n",
      "---\n",
      "\n",
      "Incorrect answers count: 3\n",
      "Pick the first 3 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      ">> Total cost: 0.009 USD, tokens used 2773\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n",
      "Correct answers: 88.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Updated the prompt instructions for clarity and accuracy.\n",
      "### Attempt 3: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 2:\n",
      "- Clarified the importance of considering social media data in the sentiment analysis.\n",
      "- Emphasized the need to leverage psychological analysis to enhance the accuracy of sentiment classification.\n",
      "- Added examples to guide the sentiment analysis process.\n",
      "### Attempt 4: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 3:\n",
      "- Clarified the instructions and examples to guide the sentiment analysis process.\n",
      "- Emphasized the importance of considering psychological aspects, emotional cues, and social media data in sentiment analysis.\n",
      "- Maintained the structure and formatting of the prompt.\n",
      "---\n",
      "\n",
      "Incorrect answers count: 3\n",
      "Pick the first 3 incorrect examples...\n",
      "\n",
      "Updating prompt...\n",
      ">> Total cost: 0.010 USD, tokens used 3060\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n",
      "Correct answers: 88.00%\n",
      "\n",
      "---\n",
      "### Attempt 1: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "First attempt.\n",
      "### Attempt 2: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 1:\n",
      "- Updated the prompt instructions for clarity and accuracy.\n",
      "### Attempt 3: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 2:\n",
      "- Clarified the importance of considering social media data in the sentiment analysis.\n",
      "- Emphasized the need to leverage psychological analysis to enhance the accuracy of sentiment classification.\n",
      "- Added examples to guide the sentiment analysis process.\n",
      "### Attempt 4: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 3:\n",
      "- Clarified the instructions and examples to guide the sentiment analysis process.\n",
      "- Emphasized the importance of considering psychological aspects, emotional cues, and social media data in sentiment analysis.\n",
      "- Maintained the structure and formatting of the prompt.\n",
      "### Attempt 5: 88.00% accuracy (3 wrong out of 25 test rows)\n",
      "Changes made to the prompt compared to attempt 4:\n",
      "- Clarified the importance of considering both positive and negative indicators in the text to determine the sentiment.\n",
      "- Provided additional guidance on how to analyze emotional cues and psychological aspects in the text.\n",
      "- Emphasized the need to interpret words and expressions in the context of social media data.\n",
      "- Added more examples to guide the sentiment analysis process.\n",
      "---\n",
      "\n",
      "\n",
      "-> Running plan 2 with mutation 1...\n",
      "\n",
      "==============\n",
      "==============\n",
      "\n",
      "Plan 2:\n",
      "Decide the sentiment of the input text. Train a machine learning model on a labeled dataset of text and corresponding sentiments. Use features such as word embeddings, n-grams, and contextual information to classify the sentiment of the input text as positive, negative, or neutral. \n",
      "\n",
      "Generating initial prompt...\n",
      ">> Total cost: 0.009 USD, tokens used 2758\n",
      "Getting chunk 1 retry 0 with 15 rows...\n",
      "Getting chunk 2 retry 0 with 10 rows...\n",
      "Correct answers: 100.00%\n",
      ">>> Goal accuracy 99% achieved for plan 2, mutation 1!\n",
      ">>> Goal accuracy 99% achieved for plan 2, mutation 1!\n",
      "\n",
      "Final prompt saved with accuracy 100.00%\n",
      "Plan 2: Machine Learning Engineer\n"
     ]
    }
   ],
   "source": [
    "# Setup the strategy executor\n",
    "# Options so far: SequentialStrategy, BasicStrategy, TreeSearchStrategy\n",
    "auto_prompt_strategy = TreeSearchStrategy(\n",
    "    model_prompt_writer=model_prompt_writer,\n",
    "    model_evaluate=model_evaluate,\n",
    "    df_original=df_all,\n",
    "    idea_seed=IDEA_SEED,\n",
    "    goal_accuracy=GOAL_ACCURACY,\n",
    "    max_attempts_per_plan=MAX_ATTEMPTS_PER_PLAN,\n",
    "    is_few_shot=IS_FEW_SHOT,\n",
    "    eval_concurrency=EVAL_CONCURRENCY,\n",
    "    rows_initial=ROWS_INITIAL,\n",
    "    rows_max=ROWS_MAX,\n",
    "    rows_incorrect=ROWS_INCORRECT,\n",
    "    is_use_eval_aware_dataset=True,\n",
    ")\n",
    "\n",
    "# Execute the strategy\n",
    "# prompt_str, accuracy, plan = auto_prompt_strategy.run()\n",
    "prompt_str, accuracy, plan = auto_prompt_strategy.run(max_mutations=1, min_acceptable_accuracy=50)\n",
    "\n",
    "# Save the final prompt\n",
    "save_log_file(\"10-prompt_final.md\", prompt_str)\n",
    "print(f\"\\nFinal prompt saved with accuracy {accuracy:.2f}%\")\n",
    "if plan is not None:\n",
    "    print(f\"Plan {plan.id}: {plan.expert_title}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
